---
title: "analysis_replication"
author: "Nicholas Judd & Torkel Klingberg"
contact: nickkjudd@gmail.com
date: "9/2/2020"
output: html_document
---

# To do

- suppress error messages
- maybe do all 3 analyses (you could enter the data raw)
- check that n is the same and that the results match the SI tables
- check spelling of everything



```{r setup, include=FALSE, echo = T}
knitr::opts_chunk$set(echo = F)

# install.packages("ggplot2"); install.packages("data.table"); install.packages("lmer"); install.packages("AICcmodavg"); install.packages("AICcmodavg"); install.packages("car")


# optional # install.packages("sjPlot"); install.packages("lattice"); install.packages("ggstance"); install.packages("jtools")
set.seed(42)
library(data.table); library(lme4); library(tidyverse); library(AICcmodavg)
```

## Training spatial cognition enhances mathematical learning - a randomized study in 17,000 children

This script will replicate the main finding using mixed effects models it is not the original script of the paper and was recoded just to double check findings. This model is the bedrock of the paper therefore we thought it best to release it so people can check it out themselves.

```{r load data, include=F, echo=F}
f <- fread("~/Projects/R_projects/spatialcognition/factor_data.csv")

# perscribed tplan percentages
tplans <- data.table(training_plan_id = c(199,203,204,218,219), 
           math = c(.485,.50,.50,.488,.488), 
           wm = c(.485,.35,.35,.215,.215),
           nvr = c(0,.135,0,0,.10),
           rot = c(0,0,.135,.10,.10),
           tang = c(.03,.015,.015,.20,.10))

cols <- names(tplans)[c(2:6)]
f <- tplans[f, on = "training_plan_id"]
#f$rotcombi_porportions <- f$rot + f$tang
#f$nvr_porportions <- f$nvr
f <- f[, (cols) := lapply(.SD, function(x) x*as.numeric(training_time)), .SDcols = cols] # multiplying by their training time for later analysis

# things that should be dummy coded in the model
f$account_id <- as.character(f$account_id)
f$training_plan_id <- factor(f$training_plan_id, 
                             levels = c("199", "203" , "204",   "218", "219"),
                             labels = c("Default", "NVR", "Rotation", "Rotation Heavy", "Mixed (NVR + Rotation)"))
f$training_time <- as.character(f$training_time)

unique(f$time) # double checking time is coded 0, 4, 6
f$time <- as.numeric(as.character(f$time)) # making time numeric for random slopes

length(unique(f$account_id)) # checking that there's 17,648 subjects
```


```{r descrip data}

table(f$cohort, f$training_plan_id) %>% kableExtra::kable(caption = "Number of subjects per cohort by training plan.") %>% kableExtra::kable_styling()

psych::describeBy(f$Math_Factor, f$time)

ggplot(f, aes(x = Math_Factor, color = as.character(time))) +
  geom_line(stat="density") +
  cowplot::theme_half_open() +
  labs(x = "Math factor scores", color = "Week of test")

```



```{r model building, include=F, echo=F, warning = F}
# adding random intercept
m1.1 <- lmer(Math_Factor ~ (1 | account_id), f)
# adding random slope
m1.2 <- lmer(Math_Factor ~ (time | account_id), f)
# adding fixed effect of time
m1.3 <- lmer(Math_Factor ~ time + (time | account_id), f, REML = F) 
# adding age brackets
m1.4 <- lmer(Math_Factor ~ time + age + (time | account_id), f, REML = F) 
# adding cohort
m1.5 <- lmer(Math_Factor ~ time + age + cohort + (time | account_id), f, REML = F) 

# adding training time
set.seed(42)
m2.1 <- lmer(Math_Factor ~ time + age + cohort + training_time + (time | account_id), f, REML = F)
# adding the interaction of training time with math test improvement
m2.2 <- lmer(Math_Factor ~ time + age + cohort + training_time + training_time:time + (time | account_id), f, REML = F)
```

### An AIC table of simple model building

```{r AICs of simplemods, include=F, echo=F, warning = F}
# comparing the AIC's
results_lmer_basemods <- aictab(c(m1.3, m1.4, m1.5, m2.1, m2.2), modnames = c('m1.3', 'm1.4', 'm1.5','m2.1', 'm2.2'))
results_lmer_basemods; # clearly showing the model fit imporving, yet these are all expect
# the models fail to converge, this is not an issue, we will come back to it.
```

```{r for the psychologists dcoded tplans}

dcoded_tplan <- lmer(Math_Factor ~ time + training_plan_id + age + cohort + training_time + training_time:time + (time | account_id), f, REML = F)
dcoded_tplan_inter <- lmer(Math_Factor ~ time*training_plan_id + age + cohort + training_time + training_time:time + (time | account_id), f, REML = F)
AIC(dcoded_tplan_inter) - AIC(dcoded_tplan) # -28 AIC dif better
AIC(dcoded_tplan_inter) - AIC(m2.2) # a little bit worse 2 AIC, probably because of the unnecessary extra terms


```


The AIC difference clearly show the model fit improving, as expected...

```{r main model, include=F, echo=F}
# adding the fixed effects of different amounts of NVR and rotation
m3.1 <- lmer(Math_Factor ~ time + age + cohort + training_time + training_time:time + nvr_porportions + rotcombi_porportions + (time | account_id), f, REML = F)
# seeing how these effect math improvement
m3.2 <- lmer(Math_Factor ~ time + age + cohort + training_time + training_time:time + nvr_porportions + rotcombi_porportions + nvr_porportions:time + rotcombi_porportions:time + (time | account_id), f, REML = F)

AIC(dcoded_tplan_inter) - AIC(m3.2) # a little bit worse 2 AIC, probably because of the unnecessary extra terms with dummy coding
# these models are quite equivilant tho, just two was to code the same thing

```


### The AIC table for different types of training

```{r dcoded model AIC table}
results_dcoded <- AICcmodavg::aictab(c(m2.2, dcoded_tplan, dcoded_tplan_inter), modnames = c('Default (inter)', 'tplans fixed','tplans interaction'))
results_dcoded

```


```{r main model AIC table}
results_spatialcognition <- AICcmodavg::aictab(c(m2.2, m3.1, m3.2), modnames = c('Default (inter)', 'nvr/rot fixed','nvr/rot interaction'))
results_spatialcognition

```
We see that the interaction model is a much better fit than the default (i.e., spatial cognitive domains ignored) or the fixed effects (baseline difference's of domains). This is both the case when we code for the amount of rotation and nvr or dummy code the training plans.

```{r plot of coefs}
library(patchwork); library(sjPlot)
sjPlot::plot_model(m3.2) + theme_minimal()


# sjPlot::plot_model(m3.2, type = "diag") # looks a lot like m2.2 which is okay (not the end of the world diagnostics) More tasks &/or more timepoints would've helped
# lattice::qqmath(m3.2, id = .05)


```


### Model treating tangram and 2d mental rotation seperate

<br>
This model is primarily for the figure and to make sure our a priori decision of combining 2d mental rotation with tangram was sound.


```{r figure model}
# this model is primarily for the figure and dto make sure our a priori decision of combining 2d mental rotation with tangram was sound.
# mixed models are better

slopes <- data.table(account_id = levels(m2.1@flist$account_id), 
                     Slopes = coef(m2.1)$account_id$time,
                     Intercept = coef(m2.1)$account_id[,1])

slopes <- f[time ==0][, .(account_id, training_plan_id, nvr, wm, rot, tang)][slopes, on = "account_id"] #needed to filter f because their 3 timepoints per subj

magnitude_assess <- lm(Slopes ~ Intercept + nvr + wm + rot + tang, data = slopes) # 

# now for the plot
slopes$Slopes.std <- as.numeric(scale(slopes$Slopes)) # making the DV standardized, we want to show minuites

magnitude_assess.std <- lm(Slopes.std ~ Intercept + nvr + wm + rot + tang, data = slopes)
summary(magnitude_assess.std)

jtools::plot_coefs(magnitude_assess.std) + coord_flip()

car::linearHypothesis(magnitude_assess.std, "rot = wm")
car::linearHypothesis(magnitude_assess.std, "tang = wm")
car::linearHypothesis(magnitude_assess.std, "tang = rot")

```

```{r, plotting results}

sjPlot::plot_model(dcoded_tplan_inter, type = "int")

sjPlot::plot_model(m3.2, type = "int")



library(ggsignif)
p<- ggplot(data_ct, aes(x=training_mins, y=Estimate, fill = training_mins)) + 
  geom_bar(stat="identity", position=position_dodge()) +
  geom_errorbar(aes(ymin=Estimate-se, ymax=Estimate+se), width=.2,
                position=position_dodge(.9)) + 
  theme_minimal(base_size = 35) +
  labs(y = "Mathematical improvement", x = "\nEffect per minute of training") +
  scale_fill_manual(values=RColorBrewer::brewer.pal(11, 'Spectral')[(8:11)]) +
  theme(legend.position = "none",
        panel.grid.minor.x=element_blank(),panel.grid.major.x=element_blank())+
  coord_cartesian(ylim=c(0,.04)) + 
  geom_signif(comparisons=list(c("Tangram", "vs-WM")), annotations="", y_position = .040, tip_length = .0, vjust=0.4, textsize = 10) +
  geom_signif(comparisons=list(c("2D Rot", "vs-WM")), annotations="", y_position = .038, tip_length = .0, vjust=0.4, textsize = 10) +
  geom_signif(comparisons=list(c("2D Rot", "Tangram")), annotations="", y_position = .036, tip_length = 0, vjust=0.4, textsize = 6) +
  geom_signif(comparisons=list(c("vs-WM", "NVR")), annotations="", y_position = .036, tip_length = 0, vjust=0.4, textsize = 6)


dd <- get_model_data(ct, type = "est")
dd$term <- recode(dd$term, nvr = 'NVR', wm = 'vs-WM', rot = '2D Rot', tang = "Tangram")
dd$term <-factor(dd$term, levels = c('Tangram', '2D Rot', 'vs-WM', 'NVR'))

fig3_natHuman <- ggplot(dd, aes(x=term, y=estimate, ymin=conf.low, ymax=conf.high, color = term)) +
  geom_pointrange(size = 2.5) +
  scale_color_manual(values=RColorBrewer::brewer.pal(11, 'Spectral')[(8:11)]) + 
  ylim(0, .05)+
  theme_minimal(base_size = 35) +
  theme(legend.position = "none",
        panel.grid.minor.x=element_blank(),panel.grid.major.x=element_blank()) +
  labs(y = "Improvement per minuite", x = "") +
  geom_signif(comparisons=list(c("Tangram", "vs-WM")), annotations="", y_position = .050, tip_length = .0, vjust=0.4, textsize = 10, color = "black") +
  geom_signif(comparisons=list(c("2D Rot", "vs-WM")), annotations="", y_position = .046, tip_length = .0, vjust=0.4, textsize = 10,  color = "black") +
  geom_signif(comparisons=list(c("2D Rot", "Tangram")), annotations="", y_position = .043, tip_length = 0, vjust=0.4, textsize = 6,  color = "black") +
  geom_signif(comparisons=list(c("vs-WM", "NVR")), annotations="", y_position = .043, tip_length = 0, vjust=0.4, textsize = 6,  color = "black")


```



### Model rohbustness checking

Checking the rohbustness of the result with outliers out. We used the Tukey Method to remove outliers by time point, there was a total of **code** data points representing **code** subjects. These subjects did not meaninfully change the result, we report the model with outliers included.

```{r outs}

# checking the rohbustness of the result with outliers out

f_outs <- f %>% 
  group_by(time) %>% 
  mutate(outs = (Math_Factor > boxplot.stats(.$Math_Factor)$stats[1] & Math_Factor < boxplot.stats(.$Math_Factor)$stats[5])) %>% 
  filter(outs == T)


# should probably do it by timepoint

m2.2_outs <- lmer(Math_Factor ~ time + age + cohort + training_time + training_time:time + (time | account_id), f_outs, REML = F)
m3.1_outs <- lmer(Math_Factor ~ time + age + cohort + training_time + training_time:time + nvr_porportions + rotcombi_porportions + (time | account_id), f_outs, REML = F)
m3.2_outs <- lmer(Math_Factor ~ time + age + cohort + training_time + training_time:time + nvr_porportions + rotcombi_porportions + nvr_porportions:time + rotcombi_porportions:time + (time | account_id), f_outs, REML = F)

AIC(m3.2_outs) - AIC(m2.2_outs)
AIC(m3.2_outs) - AIC(m3.1_outs)

fixef(m3.2)[12]; fixef(m3.2_outs)[12]
fixef(m3.2)[13]; fixef(m3.2_outs)[13]
```


```{r other modeling considerations and errors, eval=F}
# this code is kind of just dumped here, to address the model convergence failures.
# these errors are not meaningful as the results and the interpretation stays the same, it was due to coding time 0, 4, 6 instead of 0,1,2.
# we decided to continue using and report the model with timecoded as weeks since it is more interpretable

#### #### #### #### #### #### ####
#### convergence & diagnostics ####
#### #### #### #### #### #### ####

#### short story on convergence ####
# it is our coding of time, if we use 0, 1, 2; which is common in the literature the problem disappears and results stay the same

# f$time_recoded <- recode(f$time,`0` = 0L, `4` = 1L, `6` = 2L)
# m2.1_recodedT <- lmer(Math_Factor ~ time_recoded + training_time + age + cohort + (time_recoded | account_id), f, REML = F)
# m3.2_recodedT <- lmer(Math_Factor ~ time_recoded*rotcombi_porportions*nvr_porportions + age + cohort + training_time + (time_recoded | account_id), f, REML = F)
# and the 3) results stay the same
# AIC(m3.2_recodedT) - AIC(m2.1_recodedT)

#### long story on convergence; it was never actually a problem ####
# 1) convergence warnings in this case are not an issue according to Ben Blocker
# https://github.com/lme4/lme4/issues/120
# yet in some cases they can be!!! see: https://stats.stackexchange.com/questions/110004/how-scared-should-we-be-about-convergence-warnings-in-lme4
# relgrad2.1 <- with(m2.1@optinfo$derivs,solve(Hessian,gradient)); max(abs(relgrad2.1))
# relgrad4.2 <- with(m3.2@optinfo$derivs,solve(Hessian,gradient)); max(abs(relgrad3.2))

#### some diagnostics
# https://bbolker.github.io/mixedmodels-misc/ecostats_chap.html#diagnostics
# normality of residuals isn't as important as people put it out to be (Gelman & Hill + Ben Blocker)
# influ <- influence.ME::influence(m4.2, "account_id") # data is too big for this function

# plot(m2.2); qqnorm(resid(m2.2)); qqline(resid(m2.2)) # not fantastic, yet not horrible since its platykurtotic
# plot_model(m2.2, type = "diag") # non-normality of residuals isn't horrible, see graph 3
# lattice::qqmath(m2.2, id = .05)

#plot_model(m3.2, type = "diag") # looks a lot like m2.2 which is okay (not the end of the world diagnostics) More tasks &/or more timepoints would've helped
# lattice::qqmath(m3.2, id = .05)
#plt_3wayinter <- plot_model(m3.2, type = "pred", terms = c("time", "rot [0, 1]", "nvr_dummy"), ci.lvl = NA, 
#                            legend.title = "Rotation Group")


# lastly because NVR has so little variance it could be argued it should be dummy coded instead
# f$nvr_dummy <- f$nvr_porportions > 0

# dcoded_nvr <- lmer(Math_Factor ~ time + age + cohort + training_time + training_time:time + nvr_dummy + rotcombi_porportions + (time | account_id), f, REML = F)
# dcoded_nvr_inter <- lmer(Math_Factor ~ time + age + cohort + training_time + training_time:time + nvr_dummy + rotcombi_porportions + nvr_dummy:time + rotcombi_porportions:time + (time | account_id), f, REML = F)

# AICcmodavg::aictab(c(m2.2, dcoded_nvr, dcoded_nvr_inter), modnames = c('Default (inter)', 'nvr/rot fixed (dummy)','nvr/rot interaction (dummy)'))
# result still holds
```

